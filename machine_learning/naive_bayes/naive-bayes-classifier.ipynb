{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Niave Bayes Theorem\n",
    "\n",
    "## Background\n",
    "Bayes theorem: calculates the probability of an event based on the probabilities of certain related events. It is important to consider the independence of the features. \n",
    "\n",
    "Bayes theorem converts the results from a test into the real probability of the event. \n",
    "\n",
    "TODO: add more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "The data we will be using is from the UCI ML repository. You can access it [here](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "List all the files in the current directory:\n\n\u001b[34mdata\u001b[m\u001b[m                         naive-bayes-classifier.ipynb\nList of all the files inside the data directory:\nSMSSpamCollection\n"
    }
   ],
   "source": [
    "# using '!' allows us to run bash commands\n",
    "print('List all the files in the current directory:\\n')\n",
    "!ls\n",
    "print('List of all the files inside the data directory:')\n",
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  label                                        sms_message\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>sms_message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Read in the data using read_table pandas function\n",
    "df = pd.read_table('data/SMSSPamCollection',\n",
    "                    sep='\\t',\n",
    "                    header=None,\n",
    "                    names=['label', 'sms_message'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling\n",
    "Lets convert our label column to numerical values. \n",
    "where:\n",
    "- ham: 0\n",
    "- spam: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(5572, 2)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   label                                        sms_message\n0      0  Go until jurong point, crazy.. Available only ...\n1      0                      Ok lar... Joking wif u oni...\n2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n3      0  U dun say so early hor... U c already then say...\n4      0  Nah I don't think he goes to usf, he lives aro...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>sms_message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df['label'] = df.label.map({\n",
    "    'ham': 0,\n",
    "    'spam': 1\n",
    "})\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words\n",
    "As most ML algos (even within scikit learn) relly on numerical data, we will need to convert our text data to numerical data.\n",
    "\n",
    "Bag of Words (BoW) concept is a term used to describe the problems that have a bag of words, or a collection of text data that needs to be worked with. The idea is to take a piece of text and count the frequency of the words in that text. It is important to note that the BoW concept treats each word individually and the order in which the words occur does not matter.\n",
    "\n",
    "We will convert it into a matrix, so that each document/sms is a row, and each word (token) being the column. Therefore, each sms in a row will indicate which words they have by indicating the column words it has. \n",
    "\n",
    "To do this, we will be using sklearns count-vectorizer method. Which does:\n",
    "- it tokenizes the string (by separating the string (sms in our case) into separate words). It then gives an integer ID to each token\n",
    "- it counts the occurance of each of these tokens\n",
    "\n",
    "we will create our own BoW, then we will implement sklearns version.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words: our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['hi! how are you.', 'win money, win money!', 'call me bro', 'can you call me tomorrow?']\n"
    }
   ],
   "source": [
    "# We begin by setting all words to lower case\n",
    "sms = ['Hi! how are you.',\n",
    "        'Win money, win money!',\n",
    "        'call me bro',\n",
    "        'Can you call me tomorrow?']\n",
    "\n",
    "lower_case_sms = []\n",
    "\n",
    "for s in sms:\n",
    "    lower_case_sms.append(s.lower())\n",
    "print(lower_case_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['hi how are you', 'win money win money', 'call me bro', 'can you call me tomorrow']\n"
    }
   ],
   "source": [
    "# remove all punctuation\n",
    "import string\n",
    "punctuation_removed = []\n",
    "\n",
    "for s in lower_case_sms:\n",
    "    # translate() method returns a string where each character is mapped to its corresponding character in the translation table\n",
    "    # maketrans method returns a translation table with a 1-to-1 mapping of a Unicode ordinal to its translation/replacement\n",
    "    punctuation_removed.append(s.translate(str.maketrans('', '', string.punctuation)))\n",
    "print(punctuation_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['hi', 'how', 'are', 'you'], ['win', 'money', 'win', 'money'], ['call', 'me', 'bro'], ['can', 'you', 'call', 'me', 'tomorrow']]\n"
    }
   ],
   "source": [
    "# Tokenize: split up sentence into individual words using a delimiter\n",
    "split_words = []\n",
    "for word in punctuation_removed:\n",
    "    split_words.append(word.split(' '))\n",
    "print(split_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[Counter({'hi': 1, 'how': 1, 'are': 1, 'you': 1}),\n Counter({'win': 2, 'money': 2}),\n Counter({'call': 1, 'me': 1, 'bro': 1}),\n Counter({'can': 1, 'you': 1, 'call': 1, 'me': 1, 'tomorrow': 1})]\n"
    }
   ],
   "source": [
    "# Count occurance/frequency of each word\n",
    "\n",
    "# Counter method from the collections class will be used\n",
    "# counter counts the occurance of each item in the list and returns a dictionary\n",
    "import pprint\n",
    "from collections import Counter\n",
    "\n",
    "frequency_list = []\n",
    "\n",
    "for i in split_words:\n",
    "    frequence_counts = Counter(i)\n",
    "    frequency_list.append(frequence_counts)\n",
    "\n",
    "pprint.pprint(frequency_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn\n",
    "Now, lets use scikit learns implementation instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sms = ['Hiya, how are you?',\n",
    "                'Win money, win from home',\n",
    "                'call me now man',\n",
    "                'hi, call hello you tomorrow?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                tokenizer=None, vocabulary=None)\n"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "print(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['are',\n 'call',\n 'from',\n 'hello',\n 'hi',\n 'hiya',\n 'home',\n 'how',\n 'man',\n 'me',\n 'money',\n 'now',\n 'tomorrow',\n 'win',\n 'you']"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "count_vector.fit(sample_sms)\n",
    "count_vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0],\n       [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]])"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Create a matrix with the rows being each of the 4 documents, and the columns being each word\n",
    "sms_matrix = count_vector.transform(sample_sms).toarray()\n",
    "sms_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data has been cleaned into a format we can deal with. It has returned a matrix where the rows indicate a sms, and the columns indicate whether that word is present in that sms.\n",
    "\n",
    "Lets clean up the matrix and turn it into a dataframe with the right column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   are  call  from  hello  hi  hiya  home  how  man  me  money  now  tomorrow  \\\n0    1     0     0      0   0     1     0    1    0   0      0    0         0   \n1    0     0     1      0   0     0     1    0    0   0      1    0         0   \n2    0     1     0      0   0     0     0    0    1   1      0    1         0   \n3    0     1     0      1   1     0     0    0    0   0      0    0         1   \n\n   win  you  \n0    0    1  \n1    2    0  \n2    0    0  \n3    0    1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>are</th>\n      <th>call</th>\n      <th>from</th>\n      <th>hello</th>\n      <th>hi</th>\n      <th>hiya</th>\n      <th>home</th>\n      <th>how</th>\n      <th>man</th>\n      <th>me</th>\n      <th>money</th>\n      <th>now</th>\n      <th>tomorrow</th>\n      <th>win</th>\n      <th>you</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "sms_df = pd.DataFrame(sms_matrix, columns = count_vector.get_feature_names())\n",
    "sms_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], df['label'], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of rows in the df: 5572\nNumber of rows in the training set: 4179\nNumber of rows in the test set: 1393\n"
    }
   ],
   "source": [
    "print(f'Number of rows in the df: {df.shape[0]}')\n",
    "print(f'Number of rows in the training set: {X_train.shape[0]}')\n",
    "print(f'Number of rows in the test set: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply BoW to our dataset.\n",
    "\n",
    "What we will need to do:\n",
    "- Training: Learn a vocabulary dictionary (similar to the df/matrix we created earlier) for the training dataset, then transform the data into a document-term matrix\n",
    "- Testing: transform the data into a document-term matrix using the learned vocabulary from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer()\n",
    "# Fit on training data\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "# fit the test data\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "## Bayes Theorem Implementation from scratch\n",
    "We will now build the algorithm that we need to make our predictions to classify whether a message is a spam or not. \n",
    "\n",
    "But what is Bayes Theorem?\n",
    "It calculates the probability of an event occuring, based on certain other probabilities that are related to the event in question. This includes a `prior`, the probabilities that we know previously or is given to us, and the `posterior`, the probabilities that we are looking to compute using the priors.\n",
    "\n",
    "\n",
    ">$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n",
    "\n",
    "Lets define the terms above:\n",
    "- P(A|B): This is the `posterior probability` that event A happens given event B.\n",
    "- P(A): This is the probability of event A happening independentaly.\n",
    "- P(B): This is the probability of event B happening independentaly. \n",
    "- P(B|A): This is the likelihood probability of event B happening, given event A. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: What is the odds of an individual having diabetes, given that he/she tested a positive result\n",
    "Lets assume the following:\n",
    "- P(Diabetic): Is the probability of a person having diabetes. This has been given to us as 0.01 or 1%. This means, that the probability of a person in the population having diabetes is 1%\n",
    "- P(Positive): Is the probability of getting a positive result on the test\n",
    "- P(Negative): Is the probability of getting a negative result on the test\n",
    "- P(Positive|Diabetic): Is the probability of getting a positive test result given that the individual in question has diabetes. This is 0.9 or 90%. Which means, the probability of someone testing positive given that they actually have diabetes is 90%. This is also called **Sensitivity** or **TPR: True Positive Rate**.\n",
    "- P(Negative|~Diabetic): Is the probability of getting a negative test result given that the individual in question does not have diabetes. This is 0.9 or 90%. Which means the probability of someone testing negative given that they actually do not have diabetes is 90%. This is called **specificty** or **TNR: True Negative Rate**.\n",
    "\n",
    "This example would like us to find out: P(Diabetic|positive). \n",
    "\n",
    "Hence, using Bayes theorem we get:\n",
    "\n",
    "$$ P(Diabetic|Positive) = \\frac{P(Positive|Diabetic)P(Diabetic)}{P(Positive)} $$\n",
    "\n",
    "\n",
    "we can calculate P(positive) by using both sensitivity and specificity:\n",
    "\n",
    "P(Positive) = [P(Diabetic) * Sensitivity] + [P(~Diabetic) * (1 - Specificity)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the information below was given to us\n",
    "\n",
    "# P(Diabetic)\n",
    "p_diabetic = 0.01 # given to us above\n",
    "# P(~Diabetic) = 1 - P(Diabetic)\n",
    "p_not_diabetic = 1 - p_diabetic\n",
    "# Sensitivity AKA P(Positive|Diabetic)\n",
    "p_positive_given_diabetic = 0.9 # given to us above\n",
    "# Specificity or P(Negative|~Diabetic)\n",
    "p_negative_given_not_diabetic = 0.9 # given to us above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The probability of getting a positive test result is: P(Positive) = 0.108\n"
    }
   ],
   "source": [
    "# Lets work out the P(Positive)\n",
    "# This is the probability that you tested positive: combine TP and FN\n",
    "\n",
    "# TP:P(Diabetic) AND P(Positive|Diabetic)\n",
    "true_positive = p_diabetic * p_positive_given_diabetic\n",
    "# FN: P(Diabetic) AND P(Positive|Not Diabetic)\n",
    "p_positive_given_not_diabetic = 1 - p_positive_given_diabetic\n",
    "false_negative = p_not_diabetic * p_positive_given_not_diabetic\n",
    "\n",
    "# P(Positive) = TP + FN\n",
    "p_positive = true_positive + false_negative\n",
    "print(f'The probability of getting a positive test result is: P(Positive) = {round(p_positive,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate our posteriors for when we have a positive test result. \n",
    "The probability of someone being diabetic, given that they have a positive test result can be determined by *using Bayes Theorem*:\n",
    "\n",
    "When we want to find out whether someone is diabetic given that they tested positive:\n",
    "\n",
    "$$ P(Diabetic|Positive) = \\frac{P(Positive|Diabetic)P(Diabetic)}{P(Positive)} $$\n",
    "\n",
    "And when we want to find out if someone is not diabetic given that they tested positive:\n",
    "\n",
    "$$ P(~Diabetic|Positive) = \\frac{P(Positive|~Diabetic)P(~Diabetic)}{P(Positive)} $$\n",
    "\n",
    "The sum of the above posteriors add up to 1 (as the sum of posteriors always add up to 1).\n",
    "\n",
    "our goal was to determine **what is the probability of an individual having diabetes, given that they tested positive**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The probability that an individual is diabetic given that they tested positive is: P(Diabetic|Positive) = 0.083\n"
    }
   ],
   "source": [
    "# using bayes rule\n",
    "p_diabetic_given_positive = ( p_positive_given_diabetic * p_diabetic ) / p_positive\n",
    "print(f'The probability that an individual is diabetic given that they tested positive is: P(Diabetic|Positive) = {round(p_diabetic_given_positive,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now work out the probability of an individual not having diabetes, given that the individual has a positive test result:\n",
    "P(~Diabetic|Positive).\n",
    "\n",
    "This can be calculated in two ways:\n",
    "- Bayes method\n",
    "- 1 - P(Diabetic|Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The probability that an individual is not diabetic given that they tested positive is: P(~Diabetic|Positive) = 0.917\nThis is the same as working it out by doing: P(~Diabetic|Positive) = 1 - P(Diabetic|Positive = 0.917\n"
    }
   ],
   "source": [
    "# Using bayes rule\n",
    "p_not_diabetic_given_positive = ( p_positive_given_not_diabetic * p_not_diabetic ) / p_positive\n",
    "print(f'The probability that an individual is not diabetic given that they tested positive is: P(~Diabetic|Positive) = {round(p_not_diabetic_given_positive,3)}')\n",
    "print(f'This is the same as working it out by doing: P(~Diabetic|Positive) = 1 - P(Diabetic|Positive = {1 - round(p_diabetic_given_positive,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above now shows that even if you get a positive test result, there is only 8% chance that you actually have diabetes, and 91% chance you do not. BUT dont forget, this is under the assumption that 1% of the population as a whole has diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does Naive Bayes mean?\n",
    "\n",
    "The term 'Naive' in naive bayes comes from the assumption that the features that are used in the algorithm to make predictions are independent of each other, which is not always the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Implementation Example\n",
    "Lets implement Naive Bayes from scratch.\n",
    "\n",
    "Lets say we have two political party candidates:\n",
    "- Trump of the Replublican party\n",
    "- Biden of the Democratic party\n",
    "\n",
    "Lets say we are looking at the probabilities of each candidate saying one of the following words:\n",
    "- environment\n",
    "- immigration\n",
    "- reform\n",
    "\n",
    "Probabilities that the candidate says one of the following words:\n",
    "- Trump:\n",
    "    - P(Freedom|Trump): P(F|T) = 0.1\n",
    "    - P(Immigration|Trump): P(I|T) = 0.1\n",
    "    - P(Environment|Trump): P(E|T) = 0.8\n",
    "- Biden:\n",
    "    - P(Freedom|Biden): P(F|B) = 0.7\n",
    "    - P(Immigration|Biden): P(I|B) = 0.2\n",
    "    - P(Environment|Biden): P(E|B) = 0.1\n",
    "\n",
    "Lets also assume that the probability that Trump or Biden is giving a speech is: \n",
    "- P(T) = 0.5\n",
    "- P(B) = 0.5\n",
    "\n",
    "Now, given the above, what if we have to find the `probabilities of a candidate saying the words 'Freedom' or 'immigration'?`\n",
    "\n",
    "Now, we will use the Naive Bayes Theorem:\n",
    "\n",
    ">$$ P(y|x_{1}, ... , x_{n}) = \\frac{ P(y)P(x_{1},...,x_{n}|y) }{ P(x_{1},...,x_{n}) } $$\n",
    "\n",
    "- y: predictor: in our case this is the name of our candidate\n",
    "- $x_{1}%,...,$x_{n}$: are the feature vectors, the individual words\n",
    "\n",
    "The Naive Bayes Theorem makes the assumption that each of the feature vectors/words are independent of each other.\n",
    "\n",
    "The goal of this question was the work out the probability that the candidate said one of the words from Freedom or immigration. To do this, we need to calculate the posterior probabilities:\n",
    "- P(T|F,I)\n",
    "    - probability that the speech was given by trump given that the words Freedom or immigration are mentioned\n",
    "- P(B|F,I)\n",
    "    - probability that the speech was given by Biden, given that the words Freedom or immigration are mentioned\n",
    "\n",
    "We can use naive bayes theorem to calulcate it:\n",
    "\n",
    "1. $$ P(T|F,I) = \\frac{ P(T)P(F,I|T) }{ P(F,I) } $$\n",
    "\n",
    "2. $$ P(B|F,I) = \\frac{ P(B)P(F,I|B) }{ P(F,I) } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.005000000000000001\n"
    }
   ],
   "source": [
    "# Trump\n",
    "# P(T) = 0.5 \n",
    "p_t = 0.5\n",
    "# P(Freedom|Trump): P(F|T) = 0.1\n",
    "p_f_given_t = 0.1\n",
    "# P(Immigration|Trump): P(I|T) = 0.6\n",
    "p_i_given_t = 0.1\n",
    "\n",
    "\n",
    "# Probability that Trump says either environment or immigration - P(Trump)*P(Freedom)*P(Immigration)\n",
    "p_fi_given_t =  p_t * p_f_given_t * p_i_given_t\n",
    "print(p_fi_given_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'p_fi_given' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-862ce429fcad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Probability that Biden says either environment or immigration - P(Biden)*P(Freedom)*P(Immigration)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mp_fi_given_b\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mp_b\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_f_given_b\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_i_given_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_fi_given\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'p_fi_given' is not defined"
     ]
    }
   ],
   "source": [
    "# Biden\n",
    "# P(B) = 0.5 \n",
    "p_b = 0.5\n",
    "# P(Freedom|Biden): P(F|B) = 0.7\n",
    "p_f_given_b = 0.7\n",
    "# P(Immigration|Biden): P(I|B) = 0.2\n",
    "p_i_given_b = 0.2\n",
    "\n",
    "\n",
    "# Probability that Biden says either environment or immigration - P(Biden)*P(Freedom)*P(Immigration)\n",
    "p_fi_given_b =  p_b * p_f_given_b * p_i_given_b\n",
    "print(p_fi_given_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.075\n"
    }
   ],
   "source": [
    "# calculate probability of either freedom or immigration being said: P(F,I)\n",
    "p_fi = p_t_given_e_i + p_b_given_e_i\n",
    "print(p_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'p_fi_given_t' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-d14c243f1c87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# P(T|F,I) = P(F,I|T)P(T) / P(F,I)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mp_t_given_f_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mp_fi_given_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_t\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp_fi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'P(T|F,I) = {p_t_given_f_i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# P(B|F,I) = P(F,I|B)P(B) / P(F,I)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mp_b_given_f_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mp_fi_given_b\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_b\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp_fi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p_fi_given_t' is not defined"
     ]
    }
   ],
   "source": [
    "# P(T|F,I) = P(F,I|T)P(T) / P(F,I)\n",
    "p_t_given_f_i = ( p_fi_given_t * p_t ) / p_fi\n",
    "print(f'P(T|F,I) = {p_t_given_f_i}')\n",
    "# P(B|F,I) = P(F,I|B)P(B) / P(F,I)\n",
    "p_b_given_f_i = ( p_fi_given_b * p_b ) / p_fi\n",
    "print(f'P(B|F,I) = {p_b_given_f_i}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}